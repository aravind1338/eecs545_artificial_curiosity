{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'map'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fd2e8e37c9f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# import novelty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mExperience\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExperience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mManory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'map'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import novelty\n",
    "from map import Map\n",
    "from Experience import Experience\n",
    "from Memory import Manory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain():\n",
    "    \"\"\"\n",
    "    The Brain class analysis novelty\n",
    "\n",
    "    Attributes:\n",
    "        - grains: a list of PIL images from map\n",
    "        - novThresh: novelty threshold\n",
    "        - novelty_function: loss function to evaluate novelty\n",
    "    \n",
    "    Methods:\n",
    "        - CNN: will use a pre-trained CNN to perform the feature extraction (without training)\n",
    "        - AE_arch: build the architechture of autoencoder\n",
    "        - AE_compute: load trained autoencoder and compute reconstructed_vector\n",
    "        - eval_novelty: evaluates the novelty (loss) based on the input/output of Autoencoder\n",
    "        - learn_grains: performs the training of Autoencoder based on memory and new feature\n",
    "        - train_AE: manually train the autoencoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, novThresh: float, grains: list, novelty_function: novelty):\n",
    "        \"\"\"\n",
    "        Parameters: \n",
    "            - novThresh: The cutoff for the change in novelty while training\n",
    "            - novelty_function: Call a novelty funtion from the novelty module\n",
    "            - grains: a list of PIL image from map module\n",
    "        Returns: Initialization an object\n",
    "        \"\"\"\n",
    "        self.novThresh = novThresh\n",
    "        self.novelty_function = novelty_function\n",
    "        self.grains = grains   \n",
    "\n",
    "\n",
    "    def CNN(self, grains):\n",
    "        \"\"\"\n",
    "        ResNet50V2 (cut the output layer) is used to extract features\n",
    "        feature dim --> 2048\n",
    "\n",
    "        Parameters:\n",
    "            - grains: (batch, height, weight) grey imgs from map\n",
    "            reshape to (batch, 224, 224, 3) to match the ResNet50V2 model input\n",
    "        Returns:\n",
    "            - feature vector of each image (2048 dimensional) --> tensor \n",
    "        \"\"\"\n",
    "        # The following function automatically add the color channel \n",
    "        # (heigh, width) --> (height, width, 3)\n",
    "        grain_images = keras.preprocessing.image.img_to_array(grains) \n",
    "        grain_images = tf.image.per_image_standardization(grain_images)\n",
    "        # (batch, height, weight, 3) --> (batch, 224, 224, 3)\n",
    "        grain_images = tf.image.resize_with_crop_or_pad(grain_images, 224, 224)  \n",
    "\n",
    "        base_model = keras.applications.ResNet50V2(include_top=True) # load model\n",
    "        base_model.trainable = False\n",
    "        base_inputs = model.layers[0].input\n",
    "        base_outputs = model.layers[-2].output\n",
    "\n",
    "        transfer_CNN = keras.Model(inputs=base_inputs, outputs=base_outputs) # new model\n",
    "        feature_vector = transfer_CNN(grain_image)\n",
    "\n",
    "        return feature_vector # a tensor\n",
    "\n",
    "\n",
    "    def AE_arch(self):\n",
    "        \"\"\"\n",
    "        create the architecture of autoencoder\n",
    "        \"\"\"\n",
    "        # encoder\n",
    "        input_vec = layers.Input(shape = (2048,))  # ResNet50 output feature dim is 2048\n",
    "        encoder1 = layers.Dense(1024, 'sigmoid')(input_vec)\n",
    "        encoder2 = layers.Dense(512, 'sigmoid')(encoder1)\n",
    "        # decoder \n",
    "        decoder1 = layers.Dense(1024, 'sigmoid')(encoder2)\n",
    "        decoder2 = layers.Dense(2048, 'sigmoid')(decoder1)\n",
    "\n",
    "        # build model\n",
    "        autoencoder = Model(inputs=input_vec, outputs=decoder2)\n",
    "\n",
    "        return autoencoder\n",
    "\n",
    "\n",
    "    def AE_compute(self, feature_vector, trained_model=True):\n",
    "        \"\"\"\n",
    "        Parameters: \n",
    "            - feature_vector: CNN output (e.g., 2048 dim tensor)\n",
    "            - trained_model: train model/load saved model before compute reconstructed_vector\n",
    "        Returns:\n",
    "            - reconstructed_vector \n",
    "        \"\"\"\n",
    "        # create checkpoint so that autoencoder can be saved and loaded\n",
    "        checkpoint_path = \"Autoencoder/cp.ckpt\"\n",
    "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "        if saved_model:\n",
    "            autoencoder = self.AE_arch()\n",
    "            autoencoder.load_weights(checkpoint_path)\n",
    "            reconstructed_vector = autoencoder(feature_vector)\n",
    "        \n",
    "        else:\n",
    "            print(\"No trained autoencoder found\")\n",
    "\n",
    "        return reconstructed_vector \n",
    "\n",
    "\n",
    "    def learn_grains(self, feature_vector, memory=None):\n",
    "        \"\"\"\n",
    "        learn_grains trains the autoencoder to memorize the feature vector of new grains\n",
    "\n",
    "        Parameters:\n",
    "            - feature_vector: CNN output (e.g., 2048 dim tensor)\n",
    "            - memory: \n",
    "        Returns:\n",
    "            - void --> updating autoencoder\n",
    "        \"\"\"\n",
    "        # # save the model to check\n",
    "        # checkpoint_path = \"Autoencoder/cp.ckpt\"\n",
    "        # checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "        # cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "        #                                               save_weights_only=True,\n",
    "        #                                               verbose=0)\n",
    "\n",
    "        # # prepare data for training: both new feature_vectors and from memory\n",
    "\n",
    "\n",
    "        # # Call train_AE function to train autoencoder\n",
    "        # autoencoder = self.AE_arch()\n",
    "        # self.train_AE(autoencoder, train_dataset, callbacks=[cp_callback], \n",
    "        #               epochs=10, learning_rate=0.01,)\n",
    "      \n",
    "        pass\n",
    "\n",
    "\n",
    "    def eval_novelty(self, grains: list):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            - grains: a list of PIL images\n",
    "        Returns:\n",
    "            - novelty(loss) -- list float\n",
    "        \"\"\"\n",
    "        loss_list = []\n",
    "        for grain in self.grains:\n",
    "            feature_vector = self.CNN(grain)\n",
    "            reconstructed_vector = self.AE_compute(feature_vector, trained_model=True)\n",
    "            loss = self.novelty_function(feature_vector, reconstructed_vector)\n",
    "            loss_list.append(loss)\n",
    "        \n",
    "        return loss_list\n",
    "\n",
    "\n",
    "    def train_AE(self, model, train_dataset, callbacks, epochs=10, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Manually train autoencoder\n",
    "\n",
    "        Parameters:\n",
    "            - model: model to train. In this case, it is autoencoder\n",
    "            - train_dataset: new feature_vector and memory\n",
    "            - epochs, learning_rate\n",
    "            - callbacks: save the model to check\n",
    "        Return:\n",
    "            - void: train the autoencoder\n",
    "        \"\"\"\n",
    "        # optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        # loss_fn = keras.losses.MSE(vec_true, vec_pred) # could be changed\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ = \"__main__\":\n",
    "#     # init brain class\n",
    "#     novThresh = 0.1\n",
    "#     grains = Map().get_fov((0,0)) # how to load grains properly???\n",
    "#     novelty_function = novelty.l1_loss\n",
    "    \n",
    "#     brain = Brain(novThresh, grains, novelty_function)"
   ]
  }
 ]
}